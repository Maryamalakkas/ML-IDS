{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tabulate import tabulate\n",
    "import optuna\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading and Initial Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Train data\n",
    "train_data = pd.read_csv('Dataset/Train_data.csv')\n",
    "# load Test data\n",
    "test_data = pd.read_csv('Dataset/Test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    class  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  anomaly  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use the following features to train our model\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>86</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ          0          0     0   \n",
       "1         0           tcp   private   REJ          0          0     0   \n",
       "2         2           tcp  ftp_data    SF      12983          0     0   \n",
       "3         0          icmp     eco_i    SF         20          0     0   \n",
       "4         1           tcp    telnet  RSTO          0         15     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_count  dst_host_srv_count  \\\n",
       "0               0       0    0  ...             255                  10   \n",
       "1               0       0    0  ...             255                   1   \n",
       "2               0       0    0  ...             134                  86   \n",
       "3               0       0    0  ...               3                  57   \n",
       "4               0       0    0  ...              29                  86   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.04                    0.06   \n",
       "1                    0.00                    0.06   \n",
       "2                    0.61                    0.04   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.31                    0.17   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.61                         0.02   \n",
       "3                         1.00                         0.28   \n",
       "4                         0.03                         0.02   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                  1.00   \n",
       "1                   0.0                       0.0                  1.00   \n",
       "2                   0.0                       0.0                  0.00   \n",
       "3                   0.0                       0.0                  0.00   \n",
       "4                   0.0                       0.0                  0.83   \n",
       "\n",
       "   dst_host_srv_rerror_rate  \n",
       "0                      1.00  \n",
       "1                      1.00  \n",
       "2                      0.00  \n",
       "3                      0.00  \n",
       "4                      0.71  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use the following features to test our model\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25192 entries, 0 to 25191\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     25192 non-null  int64  \n",
      " 1   protocol_type                25192 non-null  object \n",
      " 2   service                      25192 non-null  object \n",
      " 3   flag                         25192 non-null  object \n",
      " 4   src_bytes                    25192 non-null  int64  \n",
      " 5   dst_bytes                    25192 non-null  int64  \n",
      " 6   land                         25192 non-null  int64  \n",
      " 7   wrong_fragment               25192 non-null  int64  \n",
      " 8   urgent                       25192 non-null  int64  \n",
      " 9   hot                          25192 non-null  int64  \n",
      " 10  num_failed_logins            25192 non-null  int64  \n",
      " 11  logged_in                    25192 non-null  int64  \n",
      " 12  num_compromised              25192 non-null  int64  \n",
      " 13  root_shell                   25192 non-null  int64  \n",
      " 14  su_attempted                 25192 non-null  int64  \n",
      " 15  num_root                     25192 non-null  int64  \n",
      " 16  num_file_creations           25192 non-null  int64  \n",
      " 17  num_shells                   25192 non-null  int64  \n",
      " 18  num_access_files             25192 non-null  int64  \n",
      " 19  num_outbound_cmds            25192 non-null  int64  \n",
      " 20  is_host_login                25192 non-null  int64  \n",
      " 21  is_guest_login               25192 non-null  int64  \n",
      " 22  count                        25192 non-null  int64  \n",
      " 23  srv_count                    25192 non-null  int64  \n",
      " 24  serror_rate                  25192 non-null  float64\n",
      " 25  srv_serror_rate              25192 non-null  float64\n",
      " 26  rerror_rate                  25192 non-null  float64\n",
      " 27  srv_rerror_rate              25192 non-null  float64\n",
      " 28  same_srv_rate                25192 non-null  float64\n",
      " 29  diff_srv_rate                25192 non-null  float64\n",
      " 30  srv_diff_host_rate           25192 non-null  float64\n",
      " 31  dst_host_count               25192 non-null  int64  \n",
      " 32  dst_host_srv_count           25192 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       25192 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       25192 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  25192 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  25192 non-null  float64\n",
      " 37  dst_host_serror_rate         25192 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     25192 non-null  float64\n",
      " 39  dst_host_rerror_rate         25192 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     25192 non-null  float64\n",
      " 41  class                        25192 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# General information and statistics about the train data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25192</td>\n",
       "      <td>25192</td>\n",
       "      <td>25192</td>\n",
       "      <td>25192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20526</td>\n",
       "      <td>8003</td>\n",
       "      <td>14973</td>\n",
       "      <td>13449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_type service   flag   class\n",
       "count          25192   25192  25192   25192\n",
       "unique             3      66     11       2\n",
       "top              tcp    http     SF  normal\n",
       "freq           20526    8003  14973   13449"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the train data\n",
    "train_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tcp', 'udp', 'icmp'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.protocol_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and duplicates\n",
    "missing_values = train_data.isnull().sum()\n",
    "total = train_data.shape[0]\n",
    "missing_columns = [col for col in train_data.columns if train_data[col].isnull().sum() > 0]\n",
    "for col in missing_columns:\n",
    "    null_count = train_data[col].isnull().sum()\n",
    "    per = (null_count/total) * 100\n",
    "    print(f\"{col}: {null_count} ({round(per, 3)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "print(f\"Number of duplicate rows: {train_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class distribution in Training set\n",
    "\n",
    "sns.countplot(x=train_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution Training set:\n",
      "normal     13449\n",
      "anomaly    11743\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Class distribution Training set:')\n",
    "print(train_data['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features\n",
    "def label_encode(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            label_encoder = LabelEncoder()\n",
    "            df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "label_encode(train_data)\n",
    "label_encode(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why drop this column?\n",
    "# The column num_outbound_cmds has only one unique value, so it is not useful for our model\n",
    "train_data.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "test_data.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "# drop hot column\n",
    "train_data.drop(['hot'], axis=1, inplace=True)\n",
    "test_data.drop(['hot'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and target\n",
    "X_train = train_data.drop(['class'], axis=1)\n",
    "Y_train = train_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_diff_srv_rate']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is happening in this code\n",
    "# Random Forest Classifier is used to rank the importance of features\n",
    "# RFE is used to select the most important features\n",
    "# we will use 5 features in our model\n",
    "# we will use the selected features to train our model\n",
    "# we will use the selected features to test our model\n",
    "\n",
    "# Feature selection using Random Forest Classifier\n",
    "rfc = DecisionTreeClassifier()  # Using Decision Tree for feature selection\n",
    "rfe = RFE(rfc, n_features_to_select=5)\n",
    "rfe = rfe.fit(X_train, Y_train)\n",
    "\n",
    "# Selecting important features\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), X_train.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data with selected features\n",
    "X_train = X_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features why? and what is the purpose of scaling?\n",
    "# Scaling is used to standardize the range of independent variables or features of the data\n",
    "# StandardScaler is used to scale the features\n",
    "# we will use the scaled features to train our model\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "test = scale.fit_transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset for training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, train_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model Training and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.015230894088745117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training a basic Decision Tree Classifier\n",
    "# Time to train the model\n",
    "clfd = DecisionTreeClassifier(criterion =\"entropy\", max_depth = 4)\n",
    "start_time = time.time()\n",
    "clfd.fit(x_train, y_train.values.ravel())\n",
    "end_time = time.time()\n",
    "print(\"Training time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time:  0.0024170875549316406\n"
     ]
    }
   ],
   "source": [
    "# Time taken to test the model\n",
    "start_time = time.time()\n",
    "y_test_pred = clfd.predict(x_train)\n",
    "end_time = time.time()\n",
    "print(\"Testing time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameter Tuning for Decision Tree using Optuna\n",
    "def objective(trial):\n",
    "    dt_max_depth = trial.suggest_int('dt_max_depth', 2, 32, log=False)\n",
    "    dt_max_features = trial.suggest_int('dt_max_features', 2, 5, log=False)\n",
    "    classifier_obj = DecisionTreeClassifier(max_features=dt_max_features, max_depth=dt_max_depth)\n",
    "    classifier_obj.fit(x_train, y_train)\n",
    "    accuracy = classifier_obj.score(x_test, y_test)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-05 21:30:05,868] A new study created in memory with name: no-name-e9d7ade7-89dc-4507-b9e1-cb2b0c2e07ce\n",
      "[I 2024-02-05 21:30:05,896] Trial 0 finished with value: 0.9939137337920084 and parameters: {'dt_max_depth': 29, 'dt_max_features': 4}. Best is trial 0 with value: 0.9939137337920084.\n",
      "[I 2024-02-05 21:30:05,916] Trial 1 finished with value: 0.9924583223074888 and parameters: {'dt_max_depth': 15, 'dt_max_features': 3}. Best is trial 0 with value: 0.9939137337920084.\n",
      "[I 2024-02-05 21:30:05,945] Trial 2 finished with value: 0.9924583223074888 and parameters: {'dt_max_depth': 22, 'dt_max_features': 5}. Best is trial 0 with value: 0.9939137337920084.\n",
      "[I 2024-02-05 21:30:05,972] Trial 3 finished with value: 0.9921937020375761 and parameters: {'dt_max_depth': 28, 'dt_max_features': 5}. Best is trial 0 with value: 0.9939137337920084.\n",
      "[I 2024-02-05 21:30:05,993] Trial 4 finished with value: 0.9940460439269648 and parameters: {'dt_max_depth': 27, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,005] Trial 5 finished with value: 0.9718179412543001 and parameters: {'dt_max_depth': 3, 'dt_max_features': 5}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,013] Trial 6 finished with value: 0.9683778777454353 and parameters: {'dt_max_depth': 4, 'dt_max_features': 2}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,033] Trial 7 finished with value: 0.9923260121725325 and parameters: {'dt_max_depth': 24, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,053] Trial 8 finished with value: 0.9940460439269648 and parameters: {'dt_max_depth': 12, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,077] Trial 9 finished with value: 0.9920613919026198 and parameters: {'dt_max_depth': 18, 'dt_max_features': 5}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,101] Trial 10 finished with value: 0.9933844932521831 and parameters: {'dt_max_depth': 30, 'dt_max_features': 3}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,126] Trial 11 finished with value: 0.9939137337920084 and parameters: {'dt_max_depth': 10, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,149] Trial 12 finished with value: 0.992590632442445 and parameters: {'dt_max_depth': 10, 'dt_max_features': 3}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,177] Trial 13 finished with value: 0.9936491135220958 and parameters: {'dt_max_depth': 15, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,198] Trial 14 finished with value: 0.989812119608362 and parameters: {'dt_max_depth': 11, 'dt_max_features': 2}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,255] Trial 15 finished with value: 0.9924583223074888 and parameters: {'dt_max_depth': 21, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,311] Trial 16 finished with value: 0.9913998412278381 and parameters: {'dt_max_depth': 24, 'dt_max_features': 3}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,347] Trial 17 finished with value: 0.9924583223074888 and parameters: {'dt_max_depth': 32, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,374] Trial 18 finished with value: 0.9875628473141043 and parameters: {'dt_max_depth': 6, 'dt_max_features': 3}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,414] Trial 19 finished with value: 0.9927229425774015 and parameters: {'dt_max_depth': 19, 'dt_max_features': 5}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,451] Trial 20 finished with value: 0.9933844932521831 and parameters: {'dt_max_depth': 13, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,483] Trial 21 finished with value: 0.9932521831172267 and parameters: {'dt_max_depth': 27, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,521] Trial 22 finished with value: 0.992590632442445 and parameters: {'dt_max_depth': 26, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,560] Trial 23 finished with value: 0.9937814236570521 and parameters: {'dt_max_depth': 32, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,593] Trial 24 finished with value: 0.9812119608362001 and parameters: {'dt_max_depth': 7, 'dt_max_features': 3}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,631] Trial 25 finished with value: 0.9927229425774015 and parameters: {'dt_max_depth': 29, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,675] Trial 26 finished with value: 0.9920613919026198 and parameters: {'dt_max_depth': 20, 'dt_max_features': 5}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,713] Trial 27 finished with value: 0.9931198729822704 and parameters: {'dt_max_depth': 24, 'dt_max_features': 4}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,747] Trial 28 finished with value: 0.9937814236570521 and parameters: {'dt_max_depth': 16, 'dt_max_features': 3}. Best is trial 4 with value: 0.9940460439269648.\n",
      "[I 2024-02-05 21:30:06,777] Trial 29 finished with value: 0.991002910822969 and parameters: {'dt_max_depth': 13, 'dt_max_features': 2}. Best is trial 4 with value: 0.9940460439269648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=4, state=TrialState.COMPLETE, values=[0.9940460439269648], datetime_start=datetime.datetime(2024, 2, 5, 21, 30, 5, 973457), datetime_complete=datetime.datetime(2024, 2, 5, 21, 30, 5, 993060), params={'dt_max_depth': 27, 'dt_max_features': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'dt_max_depth': IntDistribution(high=32, log=False, low=2, step=1), 'dt_max_features': IntDistribution(high=5, log=False, low=2, step=1)}, trial_id=4, value=None)\n"
     ]
    }
   ],
   "source": [
    "# start the optimization process\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(objective, n_trials=30)\n",
    "print(study_dt.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=27, max_features=4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training the Decision Tree model with the best parameters\n",
    "dt = DecisionTreeClassifier(max_features=study_dt.best_trial.params['dt_max_features'], max_depth=study_dt.best_trial.params['dt_max_depth'])\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9986957014857661\n",
      "Test Score: 0.9932521831172267\n"
     ]
    }
   ],
   "source": [
    "# Model Performance Metrics\n",
    "dt_train, dt_test = dt.score(x_train, y_train), dt.score(x_test, y_test)\n",
    "print(f\"Train Score: {dt_train}\")\n",
    "print(f\"Test Score: {dt_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.9910964612731081\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cross-Validation why we use cross-validation?\n",
    "# Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "# The goal of cross-validation is to test the model’s ability to predict new data that was not used in estimating it\n",
    "# we will use cross-validation to evaluate the performance of our model\n",
    "# we will use 10 folds for cross-validation\n",
    "# we will use the accuracy metric to evaluate the performance of our model\n",
    "\n",
    "scores = cross_val_score(dt, x_train, y_train, cv=10, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3498   18]\n",
      " [  33 4009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3516\n",
      "           1       1.00      0.99      0.99      4042\n",
      "\n",
      "    accuracy                           0.99      7558\n",
      "   macro avg       0.99      0.99      0.99      7558\n",
      "weighted avg       0.99      0.99      0.99      7558\n",
      "\n",
      "F1 Score: 0.9936795141901102\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report why we use these metrics?\n",
    "# Confusion matrix is used to evaluate the performance of a classification model\n",
    "# Classification report is used to measure the quality of predictions from a classification algorithm\n",
    "y_pred = dt.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤═══════════════╤══════════════╤═══════════════╤════════════╕\n",
      "│ Model         │   Train Score │   Test Score │   CV Accuracy │   F1 Score │\n",
      "╞═══════════════╪═══════════════╪══════════════╪═══════════════╪════════════╡\n",
      "│ Decision Tree │      0.998696 │     0.993252 │      0.991096 │    0.99368 │\n",
      "╘═══════════════╧═══════════════╧══════════════╧═══════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a summary table of model performance\n",
    "data = [[\"Decision Tree\", dt_train, dt_test, np.mean(scores), f1]]\n",
    "col_names = [\"Model\", \"Train Score\", \"Test Score\", \"CV Accuracy\", \"F1 Score\"]\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to decision_tree_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "model_filename = 'decision_tree_model.joblib'\n",
    "dump(dt, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = load(model_filename)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting packet capture. Press Ctrl+C to stop.\n",
      "Connection: ('20.250.58.93', 443, '172.20.10.4', 65533), Traffic Classification: Anomaly/Attack, Features: protocol_type=1, src_bytes=66, dst_bytes=0, dst_host_srv_count=1, dst_host_same_srv_rate=1.0\n",
      "Connection: ('20.250.58.93', 443, '172.20.10.4', 65533), Traffic Classification: Anomaly/Attack, Features: protocol_type=1, src_bytes=66, dst_bytes=0, dst_host_srv_count=1, dst_host_same_srv_rate=1.0\n",
      "Connection: ('172.20.10.4', 65533, '20.250.58.93', 443), Traffic Classification: Anomaly/Attack, Features: protocol_type=1, src_bytes=66, dst_bytes=0, dst_host_srv_count=1, dst_host_same_srv_rate=1.0\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import IP, TCP, UDP, sniff\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def encode_protocol(packet):\n",
    "    protocol_mapping = {'icmp': 0, 'tcp': 1, 'udp': 2}\n",
    "    if IP in packet:\n",
    "        if packet[IP].proto == 1:\n",
    "            return protocol_mapping['icmp']\n",
    "        elif packet[IP].proto == 6:\n",
    "            return protocol_mapping['tcp']\n",
    "        elif packet[IP].proto == 17:\n",
    "            return protocol_mapping['udp']\n",
    "    return -1\n",
    "\n",
    "class ConnectionTracker:\n",
    "    def __init__(self):\n",
    "        self.connections = defaultdict(lambda: {'src_bytes': 0, 'dst_bytes': 0, 'dst_host_srv_count': 0, 'dst_host_same_srv_rate': 0})\n",
    "        self.dst_host_counts = Counter()\n",
    "\n",
    "    def update_connection(self, packet):\n",
    "        if IP in packet and (TCP in packet or UDP in packet):\n",
    "            src = (packet[IP].src, packet[TCP].sport if TCP in packet else packet[UDP].sport)\n",
    "            dst = (packet[IP].dst, packet[TCP].dport if TCP in packet else packet[UDP].dport)\n",
    "            key = src + dst\n",
    "\n",
    "            if packet[IP].src == src[0]:\n",
    "                self.connections[key]['src_bytes'] += len(packet)\n",
    "            else:\n",
    "                self.connections[key]['dst_bytes'] += len(packet)\n",
    "\n",
    "            # Update counts for dst_host_srv_count\n",
    "            self.dst_host_counts[dst] += 1\n",
    "            for conn_key in self.connections:\n",
    "                if conn_key[2:] == dst:\n",
    "                    self.connections[conn_key]['dst_host_srv_count'] = self.dst_host_counts[dst]\n",
    "\n",
    "            # Calculate dst_host_same_srv_rate\n",
    "            total_connections_to_dst_host = sum(1 for k in self.connections if k[2] == dst[0])\n",
    "            if total_connections_to_dst_host > 0:\n",
    "                same_srv_rate = self.dst_host_counts[dst] / total_connections_to_dst_host\n",
    "                for conn_key in self.connections:\n",
    "                    if conn_key[2] == dst[0]:\n",
    "                        self.connections[conn_key]['dst_host_same_srv_rate'] = same_srv_rate\n",
    "\n",
    "class NetworkTrafficAnalysis:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.tracker = ConnectionTracker()\n",
    "\n",
    "    def process_packet(self, packet):\n",
    "        if IP not in packet:\n",
    "            return\n",
    "        \n",
    "        protocol_type = encode_protocol(packet)\n",
    "        self.tracker.update_connection(packet)\n",
    "        \n",
    "        for key, stats in self.tracker.connections.items():\n",
    "            features = np.array([[protocol_type, stats['src_bytes'], stats['dst_bytes'], stats['dst_host_srv_count'], stats['dst_host_same_srv_rate']]])\n",
    "            prediction = self.model.predict(features)[0]\n",
    "            traffic_type = \"Anomaly/Attack\" if prediction == 1 else \"Normal\"\n",
    "            print(f\"Connection: {key}, Traffic Classification: {traffic_type}, \" +\n",
    "                  f\"Features: protocol_type={protocol_type}, src_bytes={stats['src_bytes']}, \" +\n",
    "                  f\"dst_bytes={stats['dst_bytes']}, dst_host_srv_count={stats['dst_host_srv_count']}, \" +\n",
    "                  f\"dst_host_same_srv_rate={stats['dst_host_same_srv_rate']}\")\n",
    "\n",
    "    def start_capture(self):\n",
    "        print(\"Starting packet capture. Press Ctrl+C to stop.\")\n",
    "        sniff(prn=self.process_packet, store=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'decision_tree_model.joblib'\n",
    "    analysis_system = NetworkTrafficAnalysis(model_path)\n",
    "    analysis_system.start_capture()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (rest of your imports)\n",
    "\n",
    "class NetworkTrafficAnalysis:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.tracker = ConnectionTracker()\n",
    "        self.running = True  # Flag to control the sniffing loop\n",
    "\n",
    "    def process_packet(self, packet):\n",
    "        # ... (existing packet processing logic)\n",
    "\n",
    "    def start_capture(self):\n",
    "        print(\"Starting packet capture. Press Ctrl+C to stop.\")\n",
    "        sniff(prn=self.process_packet, store=False, stop_filter=self.should_stop_sniff)\n",
    "\n",
    "    def should_stop_sniff(self, packet):\n",
    "        return not self.running  # Stop sniffing if running is False\n",
    "\n",
    "    def stop_capture(self):\n",
    "        self.running = False  # Method to stop the capture by setting the flag to False\n",
    "\n",
    "# ... (rest of your code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
