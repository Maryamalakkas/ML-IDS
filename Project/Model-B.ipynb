{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tabulate import tabulate\n",
    "import optuna\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading and Initial Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names for the dataset\n",
    "columns = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"class\", \"difficulty_level\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'KDDTest+.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDDTrain+.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# load Test data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKDDTest+.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'KDDTest+.txt'"
     ]
    }
   ],
   "source": [
    "# load Train data\n",
    "train_data = pd.read_csv('KDDTrain+.txt', header=None, names=columns)\n",
    "# load Test data\n",
    "test_data = pd.read_csv('KDDTest+.txt', header=None, names=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "      <th>difficulty_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "     class  difficulty_level  \n",
       "0   normal                20  \n",
       "1   normal                15  \n",
       "2  neptune                19  \n",
       "3   normal                21  \n",
       "4   normal                21  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use the following features to train our model\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "      <th>difficulty_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>saint</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>mscan</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ          0          0     0   \n",
       "1         0           tcp   private   REJ          0          0     0   \n",
       "2         2           tcp  ftp_data    SF      12983          0     0   \n",
       "3         0          icmp     eco_i    SF         20          0     0   \n",
       "4         1           tcp    telnet  RSTO          0         15     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.04   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.61   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    0.31   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.06                         0.00   \n",
       "1                    0.06                         0.00   \n",
       "2                    0.04                         0.61   \n",
       "3                    0.00                         1.00   \n",
       "4                    0.17                         0.03   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                   0.0   \n",
       "1                         0.00                   0.0   \n",
       "2                         0.02                   0.0   \n",
       "3                         0.28                   0.0   \n",
       "4                         0.02                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                  1.00                      1.00   \n",
       "1                       0.0                  1.00                      1.00   \n",
       "2                       0.0                  0.00                      0.00   \n",
       "3                       0.0                  0.00                      0.00   \n",
       "4                       0.0                  0.83                      0.71   \n",
       "\n",
       "     class  difficulty_level  \n",
       "0  neptune                21  \n",
       "1  neptune                21  \n",
       "2   normal                21  \n",
       "3    saint                15  \n",
       "4    mscan                11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use the following features to test our model\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 43 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  int64  \n",
      " 1   protocol_type                125973 non-null  object \n",
      " 2   service                      125973 non-null  object \n",
      " 3   flag                         125973 non-null  object \n",
      " 4   src_bytes                    125973 non-null  int64  \n",
      " 5   dst_bytes                    125973 non-null  int64  \n",
      " 6   land                         125973 non-null  int64  \n",
      " 7   wrong_fragment               125973 non-null  int64  \n",
      " 8   urgent                       125973 non-null  int64  \n",
      " 9   hot                          125973 non-null  int64  \n",
      " 10  num_failed_logins            125973 non-null  int64  \n",
      " 11  logged_in                    125973 non-null  int64  \n",
      " 12  num_compromised              125973 non-null  int64  \n",
      " 13  root_shell                   125973 non-null  int64  \n",
      " 14  su_attempted                 125973 non-null  int64  \n",
      " 15  num_root                     125973 non-null  int64  \n",
      " 16  num_file_creations           125973 non-null  int64  \n",
      " 17  num_shells                   125973 non-null  int64  \n",
      " 18  num_access_files             125973 non-null  int64  \n",
      " 19  num_outbound_cmds            125973 non-null  int64  \n",
      " 20  is_host_login                125973 non-null  int64  \n",
      " 21  is_guest_login               125973 non-null  int64  \n",
      " 22  count                        125973 non-null  int64  \n",
      " 23  srv_count                    125973 non-null  int64  \n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  int64  \n",
      " 32  dst_host_srv_count           125973 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  class                        125973 non-null  object \n",
      " 42  difficulty_level             125973 non-null  int64  \n",
      "dtypes: float64(15), int64(24), object(4)\n",
      "memory usage: 41.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# General information and statistics about the train data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973</td>\n",
       "      <td>125973</td>\n",
       "      <td>125973</td>\n",
       "      <td>125973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>102689</td>\n",
       "      <td>40338</td>\n",
       "      <td>74945</td>\n",
       "      <td>67343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_type service    flag   class\n",
       "count         125973  125973  125973  125973\n",
       "unique             3      70      11      23\n",
       "top              tcp    http      SF  normal\n",
       "freq          102689   40338   74945   67343"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the train data\n",
    "train_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tcp', 'udp', 'icmp'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.protocol_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and duplicates\n",
    "missing_values = train_data.isnull().sum()\n",
    "total = train_data.shape[0]\n",
    "missing_columns = [col for col in train_data.columns if train_data[col].isnull().sum() > 0]\n",
    "for col in missing_columns:\n",
    "    null_count = train_data[col].isnull().sum()\n",
    "    per = (null_count/total) * 100\n",
    "    print(f\"{col}: {null_count} ({round(per, 3)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "print(f\"Number of duplicate rows: {train_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution Training set:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Class distribution Training set:')\n",
    "print(train_data['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features\n",
    "def label_encode(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            label_encoder = LabelEncoder()\n",
    "            df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "label_encode(train_data)\n",
    "label_encode(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why drop this column?\n",
    "# The column num_outbound_cmds has only one unique value, so it is not useful for our model\n",
    "train_data.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "test_data.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "# drop hot column\n",
    "train_data.drop(['hot'], axis=1, inplace=True)\n",
    "test_data.drop(['hot'], axis=1, inplace=True)\n",
    "# drop difficulty_level column\n",
    "train_data.drop(['difficulty_level'], axis=1, inplace=True)\n",
    "test_data.drop(['difficulty_level'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and target\n",
    "X_train = train_data.drop(['class'], axis=1)\n",
    "Y_train = train_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type',\n",
       " 'src_bytes',\n",
       " 'count',\n",
       " 'same_srv_rate',\n",
       " 'dst_host_diff_srv_rate']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is happening in this code\n",
    "# Random Forest Classifier is used to rank the importance of features\n",
    "# RFE is used to select the most important features\n",
    "# we will use 5 features in our model\n",
    "# we will use the selected features to train our model\n",
    "# we will use the selected features to test our model\n",
    "\n",
    "# Feature selection using Random Forest Classifier\n",
    "rfc = DecisionTreeClassifier()  # Using Decision Tree for feature selection\n",
    "rfe = RFE(rfc, n_features_to_select=5)\n",
    "rfe = rfe.fit(X_train, Y_train)\n",
    "\n",
    "# Selecting important features\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), X_train.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Protocol_type: Protocol used in the connection\n",
    "\n",
    " Src_bytes: Number of data bytes transferred from source to destination in single connection\n",
    "\n",
    "Count: Number of connections to the same destination host as the current connection in the past two seconds\n",
    "\n",
    "Same_srv_rate: The percentage of connections that were to the same service \n",
    "\n",
    "Dst_host_diff_ srv_rate: The percentage of connections that were to different services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data with selected features\n",
    "X_train = X_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features why? and what is the purpose of scaling?\n",
    "# Scaling is used to standardize the range of independent variables or features of the data\n",
    "# StandardScaler is used to scale the features\n",
    "# we will use the scaled features to train our model\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "test = scale.fit_transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset for training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, train_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model Training and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.08567070960998535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training a basic Decision Tree Classifier\n",
    "# Time to train the model\n",
    "clfd = DecisionTreeClassifier(criterion =\"entropy\", max_depth = 4)\n",
    "start_time = time.time()\n",
    "clfd.fit(x_train, y_train.values.ravel())\n",
    "end_time = time.time()\n",
    "print(\"Training time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time:  0.01191401481628418\n"
     ]
    }
   ],
   "source": [
    "# Time taken to test the model\n",
    "start_time = time.time()\n",
    "y_test_pred = clfd.predict(x_train)\n",
    "end_time = time.time()\n",
    "print(\"Testing time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameter Tuning for Decision Tree using Optuna\n",
    "def objective(trial):\n",
    "    dt_max_depth = trial.suggest_int('dt_max_depth', 2, 32, log=False)\n",
    "    dt_max_features = trial.suggest_int('dt_max_features', 2, 5, log=False)\n",
    "    classifier_obj = DecisionTreeClassifier(max_features=dt_max_features, max_depth=dt_max_depth)\n",
    "    classifier_obj.fit(x_train, y_train)\n",
    "    accuracy = classifier_obj.score(x_test, y_test)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-06 21:26:50,303] A new study created in memory with name: no-name-ad2c7aa5-ae67-41f0-bcef-900aa23c8999\n",
      "[I 2024-02-06 21:26:50,405] Trial 0 finished with value: 0.9798634631668078 and parameters: {'dt_max_depth': 25, 'dt_max_features': 3}. Best is trial 0 with value: 0.9798634631668078.\n",
      "[I 2024-02-06 21:26:50,449] Trial 1 finished with value: 0.885875317527519 and parameters: {'dt_max_depth': 3, 'dt_max_features': 2}. Best is trial 0 with value: 0.9798634631668078.\n",
      "[I 2024-02-06 21:26:50,583] Trial 2 finished with value: 0.9803926756985606 and parameters: {'dt_max_depth': 19, 'dt_max_features': 5}. Best is trial 2 with value: 0.9803926756985606.\n",
      "[I 2024-02-06 21:26:50,657] Trial 3 finished with value: 0.9717929720575783 and parameters: {'dt_max_depth': 8, 'dt_max_features': 3}. Best is trial 2 with value: 0.9803926756985606.\n",
      "[I 2024-02-06 21:26:50,743] Trial 4 finished with value: 0.9806043607112617 and parameters: {'dt_max_depth': 17, 'dt_max_features': 3}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:50,800] Trial 5 finished with value: 0.9797311600338696 and parameters: {'dt_max_depth': 12, 'dt_max_features': 2}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:50,945] Trial 6 finished with value: 0.98028683319221 and parameters: {'dt_max_depth': 17, 'dt_max_features': 5}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,016] Trial 7 finished with value: 0.9114098221845893 and parameters: {'dt_max_depth': 3, 'dt_max_features': 5}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,112] Trial 8 finished with value: 0.9758943691786621 and parameters: {'dt_max_depth': 14, 'dt_max_features': 2}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,216] Trial 9 finished with value: 0.9798370025402201 and parameters: {'dt_max_depth': 15, 'dt_max_features': 2}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,350] Trial 10 finished with value: 0.9799693056731583 and parameters: {'dt_max_depth': 29, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,554] Trial 11 finished with value: 0.9806043607112617 and parameters: {'dt_max_depth': 22, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,677] Trial 12 finished with value: 0.9799163844199831 and parameters: {'dt_max_depth': 23, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,802] Trial 13 finished with value: 0.9799957662997459 and parameters: {'dt_max_depth': 22, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:51,925] Trial 14 finished with value: 0.9797311600338696 and parameters: {'dt_max_depth': 31, 'dt_max_features': 3}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,063] Trial 15 finished with value: 0.9802603725656224 and parameters: {'dt_max_depth': 27, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,159] Trial 16 finished with value: 0.9799957662997459 and parameters: {'dt_max_depth': 20, 'dt_max_features': 3}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,258] Trial 17 finished with value: 0.978169983065199 and parameters: {'dt_max_depth': 9, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,345] Trial 18 finished with value: 0.9801280694326842 and parameters: {'dt_max_depth': 19, 'dt_max_features': 3}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,456] Trial 19 finished with value: 0.9801016088060965 and parameters: {'dt_max_depth': 25, 'dt_max_features': 4}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,553] Trial 20 finished with value: 0.9786727349703641 and parameters: {'dt_max_depth': 11, 'dt_max_features': 3}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,697] Trial 21 finished with value: 0.9802074513124471 and parameters: {'dt_max_depth': 20, 'dt_max_features': 5}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:52,877] Trial 22 finished with value: 0.9805514394580863 and parameters: {'dt_max_depth': 16, 'dt_max_features': 5}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:53,041] Trial 23 finished with value: 0.9803662150719729 and parameters: {'dt_max_depth': 16, 'dt_max_features': 5}. Best is trial 4 with value: 0.9806043607112617.\n",
      "[I 2024-02-06 21:26:53,195] Trial 24 finished with value: 0.980868966977138 and parameters: {'dt_max_depth': 13, 'dt_max_features': 5}. Best is trial 24 with value: 0.980868966977138.\n",
      "[I 2024-02-06 21:26:53,330] Trial 25 finished with value: 0.9812394157493649 and parameters: {'dt_max_depth': 12, 'dt_max_features': 4}. Best is trial 25 with value: 0.9812394157493649.\n",
      "[I 2024-02-06 21:26:53,414] Trial 26 finished with value: 0.94903683319221 and parameters: {'dt_max_depth': 6, 'dt_max_features': 3}. Best is trial 25 with value: 0.9812394157493649.\n",
      "[I 2024-02-06 21:26:53,523] Trial 27 finished with value: 0.9807895850973751 and parameters: {'dt_max_depth': 13, 'dt_max_features': 4}. Best is trial 25 with value: 0.9812394157493649.\n",
      "[I 2024-02-06 21:26:53,629] Trial 28 finished with value: 0.9811864944961897 and parameters: {'dt_max_depth': 13, 'dt_max_features': 4}. Best is trial 25 with value: 0.9812394157493649.\n",
      "[I 2024-02-06 21:26:53,741] Trial 29 finished with value: 0.9792284081287045 and parameters: {'dt_max_depth': 9, 'dt_max_features': 5}. Best is trial 25 with value: 0.9812394157493649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=25, state=TrialState.COMPLETE, values=[0.9812394157493649], datetime_start=datetime.datetime(2024, 2, 6, 21, 26, 53, 196402), datetime_complete=datetime.datetime(2024, 2, 6, 21, 26, 53, 330467), params={'dt_max_depth': 12, 'dt_max_features': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'dt_max_depth': IntDistribution(high=32, log=False, low=2, step=1), 'dt_max_features': IntDistribution(high=5, log=False, low=2, step=1)}, trial_id=25, value=None)\n"
     ]
    }
   ],
   "source": [
    "# start the optimization process\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(objective, n_trials=30)\n",
    "print(study_dt.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=12, max_features=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training the Decision Tree model with the best parameters\n",
    "dt = DecisionTreeClassifier(max_features=study_dt.best_trial.params['dt_max_features'], max_depth=study_dt.best_trial.params['dt_max_depth'])\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9837493337567049\n",
      "Test Score: 0.9806308213378493\n"
     ]
    }
   ],
   "source": [
    "# Model Performance Metrics\n",
    "dt_train, dt_test = dt.score(x_train, y_train), dt.score(x_test, y_test)\n",
    "print(f\"Train Score: {dt_train}\")\n",
    "print(f\"Test Score: {dt_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryam/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.9810729920818038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cross-Validation why we use cross-validation?\n",
    "# Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "# The goal of cross-validation is to test the model’s ability to predict new data that was not used in estimating it\n",
    "# we will use cross-validation to evaluate the performance of our model\n",
    "# we will use 10 folds for cross-validation\n",
    "# we will use the accuracy metric to evaluate the performance of our model\n",
    "\n",
    "scores = cross_val_score(dt, x_train, y_train, cv=10, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  273     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    10\n",
      "      0     0     0     0     0     0     0     0     0     1     0]\n",
      " [    0     0     0     1     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0    16     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0  1113     0     0     0     0     0     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     1     0     1     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     1     0     0 12356     0    48\n",
      "      0     0     0    11     0     6     0     0     0     0     0]\n",
      " [    0     1     0     0     0   303     0     0     0     0   131     0\n",
      "      0     0     0    26     0     0     0     0     0     0     0]\n",
      " [    2     0     0     0     0     2     0     0     1     5     4 19994\n",
      "      0     0     0    26     3     1     0     0     3    42     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0    63     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    39     0     0     0    37    15    20\n",
      "      0     0     0   758     0     4     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     4\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     8     0    10\n",
      "      0     0     0     3     0  1069     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0   794     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0   261     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    61\n",
      "      0     0     0     0     0     0     0     0     0   232     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     8\n",
      "      0     0     0     0     0     0     0     0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       276\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.94      0.94      0.94        17\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.76      1.00      0.87      1116\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      0.99      1.00     12422\n",
      "          10       0.87      0.28      0.43       461\n",
      "          11       0.99      1.00      0.99     20083\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      0.95      0.98        66\n",
      "          15       0.92      0.87      0.89       873\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.99      0.98      0.98      1090\n",
      "          18       1.00      1.00      1.00       794\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.99      1.00      0.99       262\n",
      "          21       0.84      0.79      0.82       293\n",
      "          22       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.98     37792\n",
      "   macro avg       0.49      0.47      0.47     37792\n",
      "weighted avg       0.98      0.98      0.98     37792\n",
      "\n",
      "F1 Score (Micro): 0.9806308213378493\n",
      "F1 Score (Weighted): 0.9783456655099051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryam/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/maryam/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/maryam/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report why we use these metrics?\n",
    "# Confusion matrix is used to evaluate the performance of a classification model\n",
    "# Classification report is used to measure the quality of predictions from a classification algorithm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# If you prefer 'micro' average\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"F1 Score (Micro): {f1_micro}\")\n",
    "\n",
    "# If you prefer 'weighted' average\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score (Weighted): {f1_weighted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤═══════════════╤══════════════╤═══════════════╤════════════╕\n",
      "│ Model         │   Train Score │   Test Score │   CV Accuracy │   F1 Score │\n",
      "╞═══════════════╪═══════════════╪══════════════╪═══════════════╪════════════╡\n",
      "│ Decision Tree │      0.983749 │     0.980631 │      0.981073 │   0.978346 │\n",
      "╘═══════════════╧═══════════════╧══════════════╧═══════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a summary table of model performance\n",
    "data = [[\"Decision Tree\", dt_train, dt_test, np.mean(scores), f1_weighted]]\n",
    "col_names = [\"Model\", \"Train Score\", \"Test Score\", \"CV Accuracy\", \"F1 Score\"]\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to multiclass_decision_tree_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "model_filename = 'multiclass_decision_tree_model.joblib'\n",
    "dump(dt, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = load(model_filename)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on en5 !\n",
      "WARNING: No IPv4 address found on ap1 !\n",
      "WARNING: more No IPv4 address found on awdl0 !\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NetworkTrafficAnalysis' object has no attribute 'start_capture'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     attack_types \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDoS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaint\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    144\u001b[0m }\n\u001b[1;32m    145\u001b[0m     analysis_system \u001b[38;5;241m=\u001b[39m NetworkTrafficAnalysis(model_path, attack_types)\n\u001b[0;32m--> 146\u001b[0m     \u001b[43manalysis_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_capture\u001b[49m()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting main loop...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NetworkTrafficAnalysis' object has no attribute 'start_capture'"
     ]
    }
   ],
   "source": [
    "from scapy.all import IP, TCP, UDP, sniff\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import defaultdict, Counter\n",
    "from queue import Queue\n",
    "from collections import defaultdict, Counter\n",
    "from scapy.all import IP, TCP, UDP, sniff\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialize a queue for thread-safe communication\n",
    "packet_info_queue = Queue()\n",
    "\n",
    "def encode_protocol(packet):\n",
    "    protocol_mapping = {'icmp': 0, 'tcp': 1, 'udp': 2}\n",
    "    if IP in packet:\n",
    "        if packet[IP].proto == 1:\n",
    "            return protocol_mapping['icmp']\n",
    "        elif packet[IP].proto == 6:\n",
    "            return protocol_mapping['tcp']\n",
    "        elif packet[IP].proto == 17:\n",
    "            return protocol_mapping['udp']\n",
    "    return -1\n",
    "\n",
    "class ConnectionTracker:\n",
    "    def __init__(self):\n",
    "        self.connections = defaultdict(lambda: {\n",
    "            'src_bytes': 0,\n",
    "            'dst_bytes': 0,\n",
    "            'dst_host_srv_count': 0,\n",
    "            'dst_host_same_srv_rate': 0,\n",
    "            'count': 0,\n",
    "            'dst_host_diff_srv_rate': 0,\n",
    "            'timestamps': [],\n",
    "            'services': set()\n",
    "        })\n",
    "        self.dst_host_counts = Counter()\n",
    "        self.service_counts = defaultdict(Counter)\n",
    "        \n",
    "\n",
    "    def update_connection(self, packet):\n",
    "        if IP in packet and (TCP in packet or UDP in packet):\n",
    "            src = (packet[IP].src, packet[TCP].sport if TCP in packet else packet[UDP].sport)\n",
    "            dst = (packet[IP].dst, packet[TCP].dport if TCP in packet else packet[UDP].dport)\n",
    "            service = packet[IP].dport  # Service is identified by the destination port\n",
    "            key = src + dst\n",
    "\n",
    "            if packet[IP].src == src[0]:\n",
    "                self.connections[key]['src_bytes'] += len(packet)\n",
    "            else:\n",
    "                self.connections[key]['dst_bytes'] += len(packet)\n",
    "\n",
    "            # Update the timestamp list and remove timestamps older than 2 seconds\n",
    "            current_time = time.time()\n",
    "            self.connections[key]['timestamps'] = [t for t in self.connections[key]['timestamps'] if current_time - t < 2]\n",
    "            self.connections[key]['timestamps'].append(current_time)\n",
    "\n",
    "            # Update the count for connections to the same destination host\n",
    "            self.connections[key]['count'] = len(self.connections[key]['timestamps'])\n",
    "\n",
    "            # Update services seen for this destination host\n",
    "            self.connections[key]['services'].add(service)\n",
    "            self.service_counts[dst[0]][service] += 1\n",
    "\n",
    "            # Calculate dst_host_diff_srv_rate\n",
    "            total_services = sum(self.service_counts[dst[0]].values())\n",
    "            diff_services = len(self.service_counts[dst[0]])\n",
    "            self.connections[key]['dst_host_diff_srv_rate'] = diff_services / total_services if total_services > 0 else 0\n",
    "\n",
    "            # Calculate dst_host_same_srv_rate (assuming it's the rate of the same service)\n",
    "            same_service_count = self.service_counts[dst[0]][service]\n",
    "            self.connections[key]['dst_host_same_srv_rate'] = same_service_count / total_services if total_services > 0 else 0\n",
    "\n",
    "class NetworkTrafficAnalysis:\n",
    "    def __init__(self, model_path, attack_types):\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.attack_types = attack_types\n",
    "        self.tracker = ConnectionTracker()\n",
    "\n",
    "    def process_packet(self, packet):\n",
    "        if IP not in packet:\n",
    "            return\n",
    "        \n",
    "        protocol_type = encode_protocol(packet)\n",
    "        self.tracker.update_connection(packet)\n",
    "        \n",
    "        for key, stats in self.tracker.connections.items():\n",
    "            # Assuming 'count' and 'dst_host_diff_srv_rate' are calculated within update_connection\n",
    "            count = stats.get('count', 0)\n",
    "            dst_host_diff_srv_rate = stats.get('dst_host_diff_srv_rate', 0)\n",
    "            \n",
    "            features = np.array([[protocol_type, stats['src_bytes'], count, \n",
    "                                  stats['dst_host_same_srv_rate'], dst_host_diff_srv_rate]])\n",
    "            prediction = self.model.predict(features)[0]\n",
    "            specific_category = prediction  # This should be the specific attack name\n",
    "            broader_category = self.attack_types.get(specific_category, \"Unknown\")  # Map to broader category\n",
    "\n",
    "            output = f\"{key}\\t{specific_category}/{broader_category}\\t{protocol_type}\\t\" + \\\n",
    "                     f\"{stats['src_bytes']}\\t{count}\\t\" + \\\n",
    "                     f\"{stats['dst_host_same_srv_rate']}\\t{dst_host_diff_srv_rate}\"\n",
    "\n",
    "            packet_info_queue.put(output)\n",
    "\n",
    "    \n",
    "    def start_capture(self):\n",
    "        print(\"Starting packet capture on interface...\")\n",
    "    try:\n",
    "        sniff(prn=self.process_packet, store=False)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during packet capture: {e}\")\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'multiclass_decision_tree_model.joblib'\n",
    "    attack_types = {\n",
    "    'normal': 'normal',\n",
    "    'back': 'DoS',\n",
    "    'buffer_overflow': 'U2R',\n",
    "    'ftp_write': 'R2L',\n",
    "    'guess_passwd': 'R2L',\n",
    "    'imap': 'R2L',\n",
    "    'ipsweep': 'Probe',\n",
    "    'land': 'DoS',\n",
    "    'loadmodule': 'U2R',\n",
    "    'multihop': 'R2L',\n",
    "    'neptune': 'DoS',\n",
    "    'nmap': 'Probe',\n",
    "    'perl': 'U2R',\n",
    "    'phf': 'R2L',\n",
    "    'pod': 'DoS',\n",
    "    'portsweep': 'Probe',\n",
    "    'rootkit': 'U2R',\n",
    "    'satan': 'Probe',\n",
    "    'smurf': 'DoS',\n",
    "    'spy': 'R2L',\n",
    "    'teardrop': 'DoS',\n",
    "    'warezclient': 'R2L',\n",
    "    'warezmaster': 'R2L',\n",
    "    'ipsweep': 'Probe',\n",
    "    'satan': 'Probe',\n",
    "    'portsweep': 'Probe',\n",
    "    'teardrop': 'DoS',\n",
    "    'nmap': 'Probe',\n",
    "    'saint': 'Probe'\n",
    "}\n",
    "    analysis_system = NetworkTrafficAnalysis(model_path, attack_types)\n",
    "    analysis_system.start_capture()\n",
    "    print(\"Starting main loop...\")\n",
    "    try:\n",
    "        while True:\n",
    "            if not packet_info_queue.empty():\n",
    "                print(packet_info_queue.get())\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Exiting program.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
